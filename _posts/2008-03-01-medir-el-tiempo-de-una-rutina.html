---
layout: post
title: Medir el tiempo de una rutina
date: 2008-03-01
category: cpp
tags: [cpp, programacion, optimizacion, tiempo]
---

<div class='post'>
¿Alguna vez se preocupó por la velocidad con la que corre su programa? ¿No? Entonces usted es un candidato perfecto para jugar al <a href="http://en.wikipedia.org/wiki/Java_%28board_game%29">Java</a>. En caso contrario, voy a explicarle un pequeño código que utilizaremos en próximas entregas para medir el tiempo de ejecución de determinadas rutinas.<br /><br />Ya lo dijo <a href="http://shreevatsa.wordpress.com/2008/05/16/premature-optimization-is-the-root-of-all-evil/">alguien</a>: "La optimización prematura es la raíz de todos los males". No hay nada más cierto, aunque también es verdad que hacer algo simple de la peor forma posible, es la causa de <a href="http://www.urbandictionary.com/define.php?term=pain+in+the+ass">otros grandes males</a>. Con esto quiero decir que debería intentar hacer las cosas de la forma más simple y más óptima que usted conozca (dándole mayor importancia a la simplicidad del código); luego se preocupa por "darle velocidad" a la rutina que provoca el cuello de botella (en próximos posts veremos cómo usar <em>gprof</em> para detectarlo).<br /><br />La forma de calcular el tiempo de CPU que toma una función es muy simple:<br /><ul><li>tomamos el valor del reloj antes de realizar la llamada (<em>t_ini</em>),</li><li>llamamos a la rutina en cuestión, y</li><li>tomamos nuevamente el valor del reloj (<em>t_fin</em>).</li></ul>La diferencia entre <em>t_fin - t_ini</em> nos da el total de tiempo que tomó: 1) hacer la llamada a la rutina, 2) que esta haga su trabajo, 3) que devuelva el resultado.<br /><br />Ahora hay algunos pequeños detalles de implementación. Por ejemplo, ¿qué función usar para tomar el tiempo del reloj? Y más importante, ¿qué precisión obtenemos con dicha función?<br /><br />Para tomar el tiempo podemos usar la rutina <a href="http://www.cplusplus.com/clock">clock()</a>, que devuelve el tiempo <em>aproximado</em> de CPU que transcurrió desde que nuestro programa fue iniciado, dicho tiempo representado en un valor de tipo <a href="http://www.cplusplus.com/clock_t">clock_t</a>: un valor entero que indica una cantidad de "tics" de reloj.<br /><br />La precisión que tenemos con dicha rutina es de <a href="http://www.cplusplus.com/CLOCKS_PER_SEC">CLOCKS_PER_SEC</a> (tics de reloj por segundo), lo que significa que por cada segundo que pasa, la función <em>clock()</em> nos devolverá CLOCKS_PER_SEC unidades más que el valor anterior. En MinGW, CLOCKS_PER_SEC es igual a 1000, pero es mejor no fiarse de esto, ya que en otras plataformas dicho valor varía. Inclusive, según POSIX, la constante CLOCKS_PER_SEC debería ser 1000000.<br /><br />Veamos algo de código:<br /><pre class="prettyprint">#include &lt;stdio.h&gt;<br />#include &lt;time.h&gt;<br /><br />int main(int argc, char *argv[])<br />{<br /><span> </span><span> </span>clock_t t_ini, t_fin;<br /><span> </span><span> </span>double secs;<br /><br /><span> </span><span> </span>t_ini = clock();<br /><span> </span><span> </span>/* ...hacer algo... */<br /><span> </span><span> </span>t_fin = clock();<br /><br /><span> </span><span> </span>secs = (double)(t_fin - t_ini) / CLOCKS_PER_SEC;<br /><span> </span><span> </span>printf("%.16g milisegundos\n", secs * 1000.0);<br /><span> </span><span> </span>return 0;<br />}<br /></pre>Con esto podemos medir cuántos milisegundos demoró <em>"hacer algo"</em>. Todo parece muy bonito hasta que nos damos cuenta de dos grandes problemas:<br /><ol><li>Tomar una medida única y aislada es igual que tomar un número completamente aleatorio y mostrarlo (no es una <a href="http://es.wikipedia.org/wiki/Muestra_estad%C3%ADstica">muestra representativa</a>). Es mejor repetir las mediciones unas cuantas veces (y hablo del orden de las 100, o 100000, o 1e32 veces), y luego sacar un promedio de todo.<br /></li><li>La función <span style="font-style: italic;">clock()</span> no llega a tener una precisión  ni de 10 milisegundos (aunque CLOCS_PER_SEC sea 1000 o más).</li></ol>Una vez dicho esto, el código de arriba no sirve ni para <a href="http://es.wikipedia.org/wiki/Papel_higi%C3%A9nico">limpiarse</a> los <a href="http://es.wikipedia.org/wiki/Traste">trastes</a>... Así que tenemos que buscar una función con mayor precisión, y además, promediar varias muestras.<br /><br />Existen otras alternativas como la función <a href="http://www.freebsd.org/cgi/man.cgi?query=gettimeofday">gettimeofday</a>, pero bajo Windows sufre del mismo problema de precisión que <em>clock()</em>. Igualmente en Linux funciona perfectamente, así que vale la pena tener en cuenta este código:<br /><pre class="prettyprint">#include &lt;stdio.h&gt;<br />#include &lt;time.h&gt;<br />#include &lt;sys/time.h&gt;<br /><br />/* retorna "a - b" en segundos */<br />double timeval_diff(struct timeval *a, struct timeval *b)<br />{<br /><span> </span><span> </span>return<br /><span> </span><span> </span><span> </span><span> </span>(double)(a-&gt;tv_sec + (double)a-&gt;tv_usec/1000000) -<br /><span> </span><span> </span><span> </span><span> </span>(double)(b-&gt;tv_sec + (double)b-&gt;tv_usec/1000000);<br />}<br /><br />int main(int argc, char *argv[])<br />{<br /><span> </span><span> </span>struct timeval t_ini, t_fin;<br /><span> </span><span> </span>double secs;<br /><br /><span> </span><span> </span>gettimeofday(&amp;t_ini, NULL);<br /><span> </span><span> </span>/* ...hacer algo... */<br /><span> </span><span> </span>gettimeofday(&amp;t_fin, NULL);<br /><br /><span> </span><span> </span>secs = timeval_diff(&amp;t_fin, &amp;t_ini);<br /><span> </span><span> </span>printf("%.16g milliseconds\n", secs * 1000.0);<br /><span> </span><span> </span>return 0;<br />}<br /></pre>Como puede ver la estructura <em>timeval</em> contiene dos campos, segundos y microsegundos transcurridos (tv_sec y tv_usec respectivamente), por lo tanto ofrece una precisión de microsegundos. De todas formas, como decía esto en Windows no sirve y la razón es sencilla, en la misma <a href="http://msdn2.microsoft.com/en-us/library/ms725496%28VS.85%29.aspx">MSDN</a> explican que el temporizador del sistema corre aproximadamente a unos 10 milisegundos, por lo tanto, cualquier función que lo utilice nos estará dando la misma asquerosa precisión (inclusive al utilizar <a href="http://www.google.com.ar/search?q=GetSystemTimeAsFileTime+msdn">GetSystemTimeAsFileTime</a> y <a href="http://www.google.com.ar/search?q=FILETIME+msdn">FILETIME</a>). Por lo tanto la solución es utilizar lo que se conoce en el mundo de Windows como el "contador de rendimiento de alta resolución" (<em>high-resolution performance counter</em>):<br /><pre class="prettyprint">#include &lt;stdio.h&gt;<br />#include &lt;windows.h&gt;<br /><br />/* retorna "a - b" en segundos */<br />double performancecounter_diff(LARGE_INTEGER *a, LARGE_INTEGER *b)<br />{<br /><span> </span><span> </span>LARGE_INTEGER freq;<br /><span> </span><span> </span>QueryPerformanceFrequency(&amp;freq);<br /><span> </span><span> </span>return (double)(a-&gt;QuadPart - b-&gt;QuadPart) / (double)freq.QuadPart;<br />}<br /><br />int main(int argc, char *argv[])<br />{<br /><span> </span><span> </span>LARGE_INTEGER t_ini, t_fin;<br /><span> </span><span> </span>double secs;<br /><br /><span> </span><span> </span>QueryPerformanceCounter(&amp;t_ini);<br /><span> </span><span> </span>/* ...hacer algo... */<br /><span> </span><span> </span>QueryPerformanceCounter(&amp;t_fin);<br /><br /><span> </span><span> </span>secs = performancecounter_diff(&amp;t_fin, &amp;t_ini);<br /><span> </span><span> </span>printf("%.16g milliseconds\n", secs * 1000.0);<br /><span> </span><span> </span>return 0;<br />}</pre>En este caso, imagine que <a href="http://www.google.com.ar/search?q=QueryPerformanceCounter+msdn">QueryPerformanceCounter</a> es como <em>clock()</em> y <a href="http://www.google.com.ar/search?q=QueryPerformanceFrequency+msdn">QueryPerformanceFrequency</a> es como CLOCKS_PER_SEC. Es decir, la primera función nos da el valor del contador, y la segunda su frecuencia (en ciclos por segundo, <a href="http://en.wikipedia.org/wiki/Hertz">hertz</a>). Cabe aclarar que un <a href="http://www.google.com.ar/search?q=LARGE_INTEGER+msdn">LARGE_INTEGER</a> es una forma de representar un entero de 64 bits por medio de una unión (<em>union</em>).<br /><br />Como tarea al lector, si es que existe alguno, le queda hacer una versión "portable" (entre Windows y Linux) para medir el rendimiento (con unos cuantos <em>#ifdef WIN32</em> y <em>#endif</em> sería suficiente).<br /><br /><span style="font-weight: bold;">18 de Marzo del 2008</span>: acá transcribo una macro que me pasó el amigo Carlos Becker para medir el tiempo de una rutina en Linux mediante <a href="http://www.tin.org/bin/man.cgi?section=3&topic=clock_gettime">clock_gettime</a>:<br />
<pre class="prettyprint">#define TIME_THIS(X)                                         \
  {                                                          \
    struct timespec ts1, ts2;                                \
    clock_gettime( CLOCK_REALTIME, &amp;ts1 );                   \
    X;                                                       \
    clock_gettime( CLOCK_REALTIME, &amp;ts2 );                   \
    printf( #X " demora: %f\n",                              \
      (float) ( 1.0*(1.0*ts2.tv_nsec - ts1.tv_nsec*1.0)*1e-9 \
      + 1.0*ts2.tv_sec - 1.0*ts1.tv_sec ) );                 \
  }

/* podemos usarla así */
{
  double x, y, z;
  x = 2.0;
  y = 4.0;
  TIME_THIS(z = sqrt(x*x + y*y));
}
</pre>Lo que da como resultado:
<pre class="prettyprint">z = sqrt(x*x + y*y) demora: 0.015164
</pre>
</div>
